*Status: COMPLETED*

*This. 'course' was given as a talk at [TedX Goldey Beacom](https://www.ted.com/tedx/events/32155) on [[2019-01-03]]. You can watch the recording [on youtube](https://www.youtube.com/watch?v=lq8cvQSfiMs).*

*Upon reflection, there's probably ways to integrate much of the ideas back into the rest of my [[Knowledge System]] to keep them in an evolving state, so, I might futz with the text over time tbh. Don't get too attached to its current presentation.*

*This was initially styled after the idea of a Ted Talk. I watched a bunch of them way back when I was originally writing it to try and dissect the genre conventions and suit the content to the format. Personally I think I did okay? It's not really my value judgement to make though, that's your job ğŸ˜‰*

[[Core Curiosity]]
---
*Technology is cool as shit and moving in a bajillion different fascinating directions. Here is a rapid fire exploration of these directions, some flexing to show you how cool and smart I am, and a couple fluffy and idealistic directions that I, as a cool and smart person, see happening in technology as a field.*

Outline
---
For years, we've been enchanted by the idea of magic. The thought that someone, with the wave of a wand, snap of a finger, or some special words, can completely change the world around them in an instant is an idea that has captured minds throughout history.

Right now, we live in a world where we manipulate the entirety of human knowledge on screens barely bigger than credit cards. Iâ€™d be willing to bet that everyone in this room has a device in their pocket that has more computing power than the technology we used to send people to space. And relative to the rest of human history, itâ€™s all happened in the blink of an eye. Itâ€™s really difficult to overstate how far weâ€™ve already come, even within my lifetime.

With the advent of extended reality, machine learning, and other emerging technologies, the way we work with computers and each other is going to drastically evolve over the next several years. We are increasingly able to not only perceive digital worlds in three dimensions but interact with and be seen by them in return. This is in essence, what the field of human-computer interaction is developing.

Today, Iâ€™m going to show you some HCI research projects that are pushing the boundaries of technology. I invite you to look ahead at how they will fundamentally change how we interact with computers, information, and each other.

But first, take a moment to dream with me. Itâ€™s 20XX, a Tuesday.

Imagine being a kid taking chemistry for the first time. Remember learning molecular geometry? The thing where atoms are arranged in various 3D shapes like tetrahedra and trigonal pyramidals? You had to draw them out on paper, using nothing but a pencil and ruler to visualize these abstract shapes that make up fundamental pieces of our world.

Or, maybe you were a bit luckier and did an activity where you arranged playdough and toothpicks like I did in high school. They are really sad and droopy. Instead of that, kids in 20XX play with holograms, building out octahedra and seesaws with their bare hands in space. They can manipulate atomic bonds intuitively, playing with digital representations that function as we understand things to at an atomic level.

Imagine you're out hiking and see a gorgeous landscape of mountains. Inspired by their beauty, you whip out your sketchbook, but you don't exactly have an entire collection of paints on your person. But that doesn't matter, as you draw thin wobbly lines, it transforms into a picturesque landscape painting right before your eyes.

You get home from work and jump into a game that basically puts you into the matrix. As the lone hero, you stand alone in a hostile world. Youâ€™re swarmed by agents, and dodge bullets in slow-motion using your entire body.

Now, you want to tell me that all of these sound crazy, requiring tech we donâ€™t have, right? But it turns out, â€˜20XXâ€™
is actually 2018. These are some of the things we did *last year*.

The chemistry application is Project Pupil at Carnegie Mellon. The painting? An application by Memo Akten. The slow-motion shooter? Super Hot, which you can literally go to a VR arcade to play *right now*. So, what are these things anyway? How are we doing this?

For the uninitiated, XR is used as an umbrella term to describe a continuum of combinations of real and virtual objects interacting in tandem. This includes technologies like virtual reality, where your entire environment is digital, augmented reality, where you overlay flat images onto the real world, and any dimension in between.

Maybe youâ€™ve played with primitive augmented reality systems, like Pokemon Go, or are lucky enough to have tried virtual reality system sellers like Beat Saber. The one thing XR technologies have in common is they use computers to shape your perception. XR as a spectrum can put you in wholly new and different environments, or simply add information to the real world.

Machine learning is essentially using particular algorithms to teach computers how to solve problems. Itâ€™s used in all sorts of applications, from mastering Go and powering the brains of self-driving cars,
to generate cats from a handful of lines. I drew that last one, heâ€™s probably okay. Thereâ€™s a lot of exciting work using machine learning to see the world through a computerâ€™s eyes.

We're able to take artificial intelligence and show it parts of the world. We can show them our bodies, our paintings, how objects interact, see what they come up with, and use that to shape our perception. Machine learning is able to make sense of the vast amount of information in reality, while XR will help us see it more clearly. I feel like some of the most exciting developments have been through open source and publicly funded research projects.

OpenPose is a research project at Carnegie Mellon that uses machine learning to detect bodies in single images. Itâ€™s been used as the backbone for other work, including research projects that help put your whole body in virtual reality, and help you, or at least, a video of you, do intricate ballet dances.

Pix2Pix is a project at Berkeley that uses neural networks to generate images based on training data. Itâ€™s been further remixed into applications that turn your webcam feed into flowers, or turn photos of Wilmingtonâ€™s skyline into gorgeous paintings that emulate Van Goh.

Project North Star is an augmented reality headset that you can literally 3D print anywhere in the world. Thereâ€™s a community growing around sourcing and building these headsets, and I think weâ€™ll see some interesting applications as it becomes more accessible. These are all open source, so anyone can take their work and build on top of it to make all sorts of applications, which they have.

â€œTheyâ€ includes me. Iâ€™m currently building my own North Star. Some of the parts I was able to 3D print back at the University of Delaware, others were sourced from community members that have cropped up around the project. This happened over UDâ€™s summer scholars program, where I took 10 weeks to learn the basics of XR development. After the semester started, I turned that experience into an undergraduate research project focused on getting cross-disciplinary students together to develop XR applications.

Just last week I went to Reality Virtually, a hackathon at MITâ€™s Media lab. I got together with over 400 other developers, artists, designers, and coders to make XR applications. The one rule for all projects at the hackathon was that they had to be open source, so that anyone around the world could take what they made and create new and interesting applications. Together, we made just under 100 XR projects including tools for physical therapy and accessibility, but also games and interactive art. My team made a VR escape room in under 5 days, and my advisor Dr. Barmakiâ€™s physical therapy project won â€œBest VR applicationâ€.

In my mind, this technology really comes together in the concept of Mirrorworlds. Rather than ever leaving your physical space, this technology will help transform it around you into another parallel dimension. Chairs become mountains, walls become sunsets, and "the floor is lava" transforms from a simple kid's game into a visceral experience. You can interact with digital objects the same way as you would with physical, and interact with physical ones to an even greater effect. Your environment can show you how it works, as items show you how to use them. A guitar could teach you how to play itself, showing you where best to hold it to play particular chords. Or objects could change altogether, as tables turn into touch screens and pencils into wands.

The question is no longer â€œhow can we make this work?â€ but rather â€œhow should this feel?â€ Weâ€™re at point in history where what would have been considered â€œmagicâ€ is real. Itâ€™s here, and itâ€™s now. And so, I leave you with this: What will you do with it? Thank you.

---

[project-pupil]: https://twitter.com/YujinAriza/status/1068619034827083783
[alphago]: https://www.alphagomovie.com/images/gallery/gallery-9.jpg
[pat]: "the use of math and code to find underlying patterns in data to solve problems that traditional programming approaches cannot"
[cat]: some of mom's cats
[dog]: diesel recognized by a neural net as, in fact, a dog
[pets]: all the pets
[mixed-reality-spectrum]: https://docs.microsoft.com/en-us/windows/mixed-reality/images/mixed-reality-spectrum-550px.png
[Intel]: https://youtu.be/VSHDyUXSNqY?t=1069
[sad-toothpick]: https://photos.app.goo.gl/d4FFiHeLDzRsa3916
[matrix]: https://youtu.be/xZ0OUq_kDh8?t=20
[super-hot]: https://www.youtube.com/watch?v=pzG7Wc6mbwE
[leap-light]: https://twitter.com/keiichiban/status/1034475041650630656
[mirror]: http://blog.leapmotion.com/mirrorworlds/
[david]: â€œItâ€™s time to shift the conversation from what an AR system should look like, to what an AR experience should feel like.â€ - DAVID HOLZ co-founder and chief technology officer at Leap Motion.
[magic]: Any sufficiently advanced technology is indistinguishable from magic.
[painting]: https://vimeo.com/302624466
[corning]: youtu.be/jZkHpNnXLB0

Bibliography
---
- __Music Everywhere__, www.etc.cmu.edu/projects/pupil/.
- â€œAlphaGo.â€ __Wikipedia__, Wikimedia Foundation, 18 Dec. 2018, en.wikipedia.org/wiki/AlphaGo.
- Ariza, Yujin. â€œMore Players? Why Not Pic.twitter.com/WcrF5w30hV.â€ __Twitter__, Twitter, 30 Nov. 2018, twitter.com/YujinAriza/status/1068619034827083783.
- â€œBadass Fingersnap.â€ __TV Tropes__, tvtropes.org/pmwiki/pmwiki.php/Main/BadassFingerSnap.
- â€œBuilding a Gesture Recognition System Using Deep Learning - Joanna MaterzyÅ„ska.â€ __YouTube__, YouTube, 13 Nov. 2017, youtu.be/keffWSqi67w.
- â€œBut for Me, It Was Tuesday.â€ __TV Tropes__, tvtropes.org/pmwiki/pmwiki.php/Main/ButForMeItWasTuesday.
- CMU-Perceptual-Computing-Lab. â€œCMU-Perceptual-Computing-Lab/Openpose.â€ __GitHub__, 8 Jan. 2019, github.com/CMU-Perceptual-Computing-Lab/openpose.
- â€œClarke's Three Laws.â€ __Wikipedia__, Wikimedia Foundation, 26 Dec. 2018, en.wikipedia.org/wiki/Clarke's_three_laws.
- â€œA Day Made of Glass 2: Same Day. Expanded Corning Vision (2012).â€ __YouTube__, YouTube, 3 Feb. 2012, youtu.be/jZkHpNnXLB0.
- â€œA Day Made of Glass... Made Possible by Corning. (2011).â€ __YouTube__, YouTube, 7 Feb. 2011, youtu.be/6Cf7IL_eZ38.
- â€œDeep Learning for VR/AR: Body Tracking.â€ __Intel RealSense__, realsense.intel.com/deep-learning-for-vr-ar/.
- â€œDeep Learning for VR/AR: Body Tracking with Intel RealSense Technology.â€ __YouTube__, YouTube, 29 Nov. 2018, youtu.be/VSHDyUXSNqY.
- â€œDensePose.â€ __DensePose__, densepose.org/.
- â€œThe End of Cloud Computing.â€ __YouTube__, YouTube, 15 July 2017, youtu.be/4QTAtFaIiyc.
- â€œFei-Fei Li on AI and Machine Learning.â€ __YouTube__, YouTube, 5 Feb. 2018, youtu.be/XlnbNFW2tX8.
- â€œFull-Contact Magic.â€ __TV Tropes__, tvtropes.org/pmwiki/pmwiki.php/Main/FullContactMagic.
- â€œGoogle Developer Day at GDC 2018 Livestream.â€ __YouTube__, YouTube, 19 Mar. 2018, youtu.be/5wtlj_q3DjE.
- â€œHow to Write a Conference Talk - The PL Enthusiast.â€ __The Programming Languages Enthusiast__, 2 Jan. 2019, www.pl-enthusiast.net/2019/01/02/how-to-write-a-conference-talk/.
- Jezra. â€œHow to Create Your TED Talk: An 8-Step Process.â€ __Speak Up For Success__, 10 Oct. 2018, speakupforsuccess.com/create-a-ted-talk/.
- Kipman, Alex. â€œA Futuristic Vision of the Age of Holograms.â€ __Ted__, Ted, www.ted.com/talks/alex_kipman_the_dawn_of_the_age_of_holograms.
- â€œLearning to See.â€ __Memo Akten__, www.memo.tv/portfolio/learning-to-see/.
- â€œLearning to See: Gloomy Sunday.â€ __Vimeo__, 12 Jan. 2019, vimeo.com/260612034.
- â€œLearning to See: We Are Made of Star Dust (#2).â€ __Vimeo__, 12 Jan. 2019, vimeo.com/242498070.
- Li, Fei-Fei. â€œHow We're Teaching Computers to Understand Pictures.â€ __Ted__, Ted, www.ted.com/talks/fei_fei_li_how_we_re_teaching_computers_to_understand_pictures.
- â€œMagical Gesture.â€ __TV Tropes__, tvtropes.org/pmwiki/pmwiki.php/Main/MagicalGesture.
- Matsuda, Keiichi. â€œHYPER-REALITY.â€ __YouTube__, YouTube, 19 May 2016, www.youtube.com/watch?v=YJg02ivYzSs.
- Matsuda, Keiichi. â€œUsing [[ProjectNorthStar]] to Tap Back in to Physical Reality. Lots of Possibilities Spring from Combining [[AR]] with [[IoT]]. @Tweethue Pic.twitter.com/triANhovp7.â€ __Twitter__, Twitter, 28 Aug. 2018, twitter.com/keiichiban/status/1034475041650630656.
- â€œMaureen Fan Explains the Power of VR and Animation.â€ __YouTube__, YouTube, 5 Feb. 2018, youtu.be/1xVyQhthH3s.
- â€œMirrorworlds.â€ __Leap Motion Blog__, 16 July 2018, blog.leapmotion.com/mirrorworlds/.
- Motion, Leap. â€œâ€˜It's Weird That a Child with a Piece of Clay Has More Power than a Professional with a Computer." This Week, Leap Motion Was Featured in the @WSJ as Part of a Larger Conversation around Interfaces of the Future. Https://T.co/DCde8I0MwI.â€ __Twitter__, Twitter, 4 Oct. 2018, twitter.com/LeapMotion/status/1047833574689452034.
- â€œThe Next Leap: How A.I. Will Change the 3D Industry - Andrew Price.â€ __YouTube__, YouTube, 5 Nov. 2018, youtu.be/FlgLxSLsYWQ.
- â€œOhayo (ã‚ªãƒãƒ¨ã‚¦) Satoshi Kon.â€ __YouTube__, YouTube, 5 Dec. 2010, youtu.be/qYUFBnAmK28.
- â€œOrigami: ReImagining Reality.â€ __Procedural Worlds__, 21 Mar. 2018, www.procedural-worlds.com/blog/origami-reimagining-reality/.
- â€œThe Potential of Shared Virtual Reality | Bruce Wooden | TEDxGeneva.â€ __YouTube__, YouTube, 16 June 2016, youtu.be/7mL0E4ykS7E.
- â€œProject North Star.â€ __Leap Motion Developer__, developer.leapmotion.com/northstar/.
- â€œProject North Star Is Now Open Source.â€ __Leap Motion Blog__, 6 June 2018, blog.leapmotion.com/north-star-open-source/.
- â€œProject North Star: Exploring Augmented Reality.â€ __YouTube__, YouTube, 11 Apr. 2018, youtu.be/7m6J8W6Ib4w.
- Raskin, Andy. â€œThe Greatest Sales Deck I've Ever Seen â€“ The Mission â€“ Medium.â€ __Medium.com__, Medium, 15 Sept. 2016, medium.com/the-mission/the-greatest-sales-deck-ive-ever-seen-4f4ef3391ba0.
- Raskin, Andy. â€œWant a Better Pitch? Watch This. â€“ Firm Narrative â€“ Medium.â€ __Medium.com__, Medium, 13 July 2015, medium.com/firm-narrative/want-a-better-pitch-watch-this-328b95c2fd0b.
- â€œReal-World Games Â |Â  Google Maps Platform Â |Â  Google Cloud.â€ __Google__, Google, cloud.google.com/maps-platform/gaming/.
- SUPERHOT. â€œSUPERHOT VR Release Trailer.â€ __YouTube__, YouTube, 5 Dec. 2016, www.youtube.com/watch?v=pzG7Wc6mbwE.
- â€œSorcerer's Apprentice - Fantasia.â€ __Disney Video__, video.disney.com/watch/sorcerer-s-apprentice-fantasia-4ea9ebc01a74ea59a5867853.
- Stillman, Jessica. â€œ5 Steps to Making Pitches Like Elon Musk.â€ __Inc.com__, Inc., 22 July 2015, www.inc.com/jessica-stillman/5-steps-to-pitch-like-elon-musk.html.
- â€œSummoning and Superpowers: Designing VR Interactions at a Distance.â€ __Leap Motion Blog__, 25 Jan. 2018, blog.leapmotion.com/summoning-superpowers-designing-vr-interactions-distance/.
- â€œTechnology.â€ __Leap Motion__, www.leapmotion.com/technology/.
- â€œUnveiling Project North Star.â€ __Leap Motion Blog__, 28 June 2018, blog.leapmotion.com/northstar/.
- â€œWhat is the Next Generation of Human-Computer Interaction?â€ CHI 2006 Workshop Proceedings, cs.tufts.edu/~jacob/workshop/report.pdf.
- â€œEntering the Metaverse.â€ Liv Erickson, livi.link/entering-metaverse-pdf.
- â€œThe Chess Master and the Computerâ€ Garry Kasparov marom.net.technion.ac.il/files/2016/07/Kasparov-2010.pdf
- â€œHow combined human and computer intelligence will redefine jobsâ€ Brad Bush techcrunch.com/2016/11/01/how-combined-human-and-computer-intelligence-will-redefine-jobs/
- https://theinternettimessupplement.wordpress.com/2013/03/15/st-peters-square-2005-v-2013/
- https://courses.lumenlearning.com/boundless-chemistry/chapter/molecular-geometry/

![[Cyberstalk Me]]